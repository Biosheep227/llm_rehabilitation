{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741829608.555014 1129901 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1741829608.666700 1133068 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741829608.681249 1133075 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import pyttsx3\n",
    "import time\n",
    "from PyQt6.QtCore import QThread, Qt, pyqtSignal, pyqtSlot\n",
    "from PyQt6.QtGui import QImage, QPixmap, QFont\n",
    "from PyQt6.QtWidgets import (QApplication, QMainWindow, QLabel, \n",
    "                            QLineEdit, QVBoxLayout, QWidget, \n",
    "                            QPushButton, QMessageBox)\n",
    "\n",
    "# 初始化MediaPipe和pyttsx3\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 09:33:30.004 python[24405:1129901] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    }
   ],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    # a, b, c 为三个点的坐标\n",
    "    ab = [b[0] - a[0], b[1] - a[1]]  # 向量 AB\n",
    "    bc = [c[0] - b[0], c[1] - b[1]]  # 向量 BC\n",
    "    \n",
    "    # 计算向量的点积\n",
    "    dot_product = ab[0] * bc[0] + ab[1] * bc[1]\n",
    "    \n",
    "    # 计算向量的叉积\n",
    "    cross_product = ab[0] * bc[1] - ab[1] * bc[0]\n",
    "    \n",
    "    # 计算夹角\n",
    "    angle = math.degrees(math.atan2(abs(cross_product), dot_product))\n",
    "    return angle\n",
    "\n",
    "def speak(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# 初始化摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 用来控制是否已抬腿\n",
    "leg_raised = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # 转换为RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 获取人体关键点\n",
    "    results = pose.process(frame_rgb)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        # 提取关节坐标\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        \n",
    "        # 获取左肩、左髋、左膝、左踝、左脚大拇指的坐标\n",
    "        left_shoulder = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y)\n",
    "        left_hip = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)\n",
    "        left_knee = (landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y)\n",
    "        left_ankle = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)\n",
    "        left_big_toe = (landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].x, landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].y)\n",
    "\n",
    "        # 计算髋部、膝部、踝部的角度\n",
    "        hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)  # 髋关节角度\n",
    "        knee_angle = calculate_angle(left_hip, left_knee, left_ankle)  # 膝关节角度\n",
    "        ankle_angle = calculate_angle(left_knee, left_ankle, left_big_toe)  # 踝关节角度\n",
    "\n",
    "        # 计算补角\n",
    "        hip_angle_complement = 180 - hip_angle  # 髋关节补角\n",
    "        knee_angle_complement = 180 - knee_angle  # 膝关节补角\n",
    "        ankle_angle_complement = 180 - ankle_angle  # 踝关节补角\n",
    "\n",
    "        # 在图像上显示角度数字\n",
    "        # 计算适当的位置来标示角度数值\n",
    "        cv2.putText(frame, f\"{hip_angle_complement:.2f}°\", \n",
    "                    (int(left_hip[0] * frame.shape[1]) + 10, int(left_hip[1] * frame.shape[0]) - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{knee_angle_complement:.2f}°\", \n",
    "                    (int(left_knee[0] * frame.shape[1]) + 10, int(left_knee[1] * frame.shape[0]) - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{ankle_angle_complement:.2f}°\", \n",
    "                    (int(left_ankle[0] * frame.shape[1]) + 10, int(left_ankle[1] * frame.shape[0]) - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # 计算左肩、左髋、左膝、左踝之间的连线\n",
    "        cv2.line(frame, (int(left_shoulder[0] * frame.shape[1]), int(left_shoulder[1] * frame.shape[0])), \n",
    "                 (int(left_hip[0] * frame.shape[1]), int(left_hip[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接肩膀和髋\n",
    "        cv2.line(frame, (int(left_hip[0] * frame.shape[1]), int(left_hip[1] * frame.shape[0])), \n",
    "                 (int(left_knee[0] * frame.shape[1]), int(left_knee[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接髋和膝\n",
    "        cv2.line(frame, (int(left_knee[0] * frame.shape[1]), int(left_knee[1] * frame.shape[0])), \n",
    "                 (int(left_ankle[0] * frame.shape[1]), int(left_ankle[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接膝和踝\n",
    "        cv2.line(frame, (int(left_ankle[0] * frame.shape[1]), int(left_ankle[1] * frame.shape[0])), \n",
    "                 (int(left_big_toe[0] * frame.shape[1]), int(left_big_toe[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接踝和大拇指\n",
    "\n",
    "        # 绘制圆圈表示关键点\n",
    "        cv2.circle(frame, (int(left_shoulder[0] * frame.shape[1]), int(left_shoulder[1] * frame.shape[0])), 5, (0, 0, 255), -1)  # 左肩\n",
    "        cv2.circle(frame, (int(left_hip[0] * frame.shape[1]), int(left_hip[1] * frame.shape[0])), 5, (0, 255, 255), -1)  # 左髋\n",
    "        cv2.circle(frame, (int(left_knee[0] * frame.shape[1]), int(left_knee[1] * frame.shape[0])), 5, (255, 0, 0), -1)  # 左膝\n",
    "        cv2.circle(frame, (int(left_ankle[0] * frame.shape[1]), int(left_ankle[1] * frame.shape[0])), 5, (255, 255, 0), -1)  # 左踝\n",
    "        cv2.circle(frame, (int(left_big_toe[0] * frame.shape[1]), int(left_big_toe[1] * frame.shape[0])), 5, (255, 0, 255), -1)  # 左脚大拇指\n",
    "\n",
    "        # 检查角度范围并语音播报\n",
    "        if (100 < ankle_angle_complement < 110) and (173 < knee_angle_complement < 180) and (175 < hip_angle_complement < 180):\n",
    "            speak(\"请抬腿\")\n",
    "            leg_raised = True\n",
    "\n",
    "        # 检测用户是否抬腿并检查膝关节\n",
    "        if leg_raised:\n",
    "            # 如果髋关节补角小于150度\n",
    "            if hip_angle_complement < 150:\n",
    "                if knee_angle_complement < 170:\n",
    "                    speak(\"膝关节未伸直\")\n",
    "                elif hip_angle > 55:\n",
    "                    if hip_angle < 70:\n",
    "                        speak(\"正常\")\n",
    "                    if hip_angle > 70:\n",
    "                        speak(\"优秀\")\n",
    "\n",
    "    # 显示结果\n",
    "    cv2.imshow(\"Pose Detection\", frame)\n",
    "\n",
    "    # 按'q'键退出\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741832745.635056 1198250 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1741832745.729522 1198749 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741832745.741702 1198749 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-03-13 10:25:47.176 python[25760:1198250] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-13 10:25:47.177 python[25760:1198250] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "2025-03-13 10:25:47.410 python[25760:1198801] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "W0000 00:00:1741832748.710698 1198756 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2025-03-13 10:25:51.390 python[25760:1198250] TSM AdjustCapsLockLEDForKeyTransitionHandling - _ISSetPhysicalKeyboardCapsLockLED Inhibit\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zehaokou/miniconda3/envs/rehab/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "from PyQt6.QtCore import QThread, Qt, pyqtSignal, pyqtSlot\n",
    "from PyQt6.QtGui import QImage, QPixmap, QFont\n",
    "from PyQt6.QtWidgets import (QApplication, QMainWindow, QLabel, \n",
    "                            QLineEdit, QVBoxLayout, QWidget, \n",
    "                            QPushButton, QMessageBox,QHBoxLayout)\n",
    "\n",
    "# 初始化MediaPipe姿势识别模型\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 初始化语音引擎\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"计算三个关节点的角度\"\"\"\n",
    "    ab = [b[0] - a[0], b[1] - a[1]]\n",
    "    bc = [c[0] - b[0], c[1] - b[1]]\n",
    "    \n",
    "    dot_product = ab[0] * bc[0] + ab[1] * bc[1]\n",
    "    cross_product = ab[0] * bc[1] - ab[1] * bc[0]\n",
    "    \n",
    "    angle = math.degrees(math.atan2(abs(cross_product), dot_product))\n",
    "    return angle\n",
    "\n",
    "class VideoThread(QThread):\n",
    "    change_pixmap = pyqtSignal(QImage)\n",
    "    save_signal = pyqtSignal()\n",
    "    speak_signal = pyqtSignal(str)\n",
    "    error_signal = pyqtSignal(str)\n",
    "    capture_signal = pyqtSignal()  \n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.subject_id = \"\"\n",
    "        self.stable_start = None\n",
    "        self.target_angle = None\n",
    "        self.current_frame = None\n",
    "        self.running = True\n",
    "        self.leg_raised = False\n",
    "        self.capture_signal.connect(self.manual_capture)\n",
    "\n",
    "    @pyqtSlot()\n",
    "    def manual_capture(self):\n",
    "        \"\"\"手动捕获当前帧\"\"\"\n",
    "        if self.current_frame is not None:\n",
    "            self.save_signal.emit()\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            self.error_signal.emit(\"无法打开摄像头\")\n",
    "            return\n",
    "\n",
    "        while self.running and cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            # 姿势检测处理\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(frame_rgb)\n",
    "            self.current_frame = frame.copy()\n",
    "\n",
    "            try:\n",
    "                if results.pose_landmarks:\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    \n",
    "                    # 获取关节坐标（左半身）\n",
    "                    left_shoulder = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y)\n",
    "                    left_hip = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)\n",
    "                    left_knee = (landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y)\n",
    "                    left_ankle = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x,\n",
    "                                 landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)\n",
    "                    left_big_toe = (landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].x,\n",
    "                                   landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].y)\n",
    "\n",
    "                    # 计算关节角度（补角）\n",
    "                    hip_angle = 180 - calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "                    knee_angle = 180 - calculate_angle(left_hip, left_knee, left_ankle)\n",
    "                    ankle_angle = 180 - calculate_angle(left_knee, left_ankle, left_big_toe)\n",
    "\n",
    "                    # 绘制姿势标记\n",
    "                    # 在BGR帧上绘制，后续需要转换为RGB\n",
    "                    cv2.putText(frame, f\"{hip_angle:.1f} degree\", \n",
    "                              (int(left_hip[0] * frame.shape[1]) + 10, \n",
    "                               int(left_hip[1] * frame.shape[0]) - 10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    \n",
    "                    # 关节连线（代码保持原有逻辑）\n",
    "                    cv2.putText(frame, f\"{hip_angle:.2f} degree\", \n",
    "                                (int(left_hip[0] * frame.shape[1]) + 10, int(left_hip[1] * frame.shape[0]) - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"{knee_angle:.2f} degree\", \n",
    "                                (int(left_knee[0] * frame.shape[1]) + 10, int(left_knee[1] * frame.shape[0]) - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"{ankle_angle:.2f} degree\", \n",
    "                                (int(left_ankle[0] * frame.shape[1]) + 10, int(left_ankle[1] * frame.shape[0]) - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                    # 计算左肩、左髋、左膝、左踝之间的连线\n",
    "                    cv2.line(frame, (int(left_shoulder[0] * frame.shape[1]), int(left_shoulder[1] * frame.shape[0])), \n",
    "                            (int(left_hip[0] * frame.shape[1]), int(left_hip[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接肩膀和髋\n",
    "                    cv2.line(frame, (int(left_hip[0] * frame.shape[1]), int(left_hip[1] * frame.shape[0])), \n",
    "                            (int(left_knee[0] * frame.shape[1]), int(left_knee[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接髋和膝\n",
    "                    cv2.line(frame, (int(left_knee[0] * frame.shape[1]), int(left_knee[1] * frame.shape[0])), \n",
    "                            (int(left_ankle[0] * frame.shape[1]), int(left_ankle[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接膝和踝\n",
    "                    cv2.line(frame, (int(left_ankle[0] * frame.shape[1]), int(left_ankle[1] * frame.shape[0])), \n",
    "                            (int(left_big_toe[0] * frame.shape[1]), int(left_big_toe[1] * frame.shape[0])), (0, 255, 0), 2)  # 连接踝和大拇指\n",
    "\n",
    "                    # 绘制圆圈表示关键点\n",
    "                    cv2.circle(frame, (int(left_shoulder[0] * frame.shape[1]), int(left_shoulder[1] * frame.shape[0])), 5, (0, 0, 255), -1)  # 左肩\n",
    "                    cv2.circle(frame, (int(left_hip[0] * frame.shape[1]), int(left_hip[1] * frame.shape[0])), 5, (0, 255, 255), -1)  # 左髋\n",
    "                    cv2.circle(frame, (int(left_knee[0] * frame.shape[1]), int(left_knee[1] * frame.shape[0])), 5, (255, 0, 0), -1)  # 左膝\n",
    "                    cv2.circle(frame, (int(left_ankle[0] * frame.shape[1]), int(left_ankle[1] * frame.shape[0])), 5, (255, 255, 0), -1)  # 左踝\n",
    "                    cv2.circle(frame, (int(left_big_toe[0] * frame.shape[1]), int(left_big_toe[1] * frame.shape[0])), 5, (255, 0, 255), -1)  # 左脚大拇指\n",
    "\n",
    "                    annotated_frame = frame.copy()\n",
    "                    cv2.putText(annotated_frame, f\"kuan: {hip_angle:.2f} degree\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_frame, f\"xi: {knee_angle:.2f} degree\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_frame, f\"huai: {ankle_angle:.2f} degree\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                    # 姿势条件判断\n",
    "                    if (100 < ankle_angle < 110) and (173 < knee_angle < 180) and (175 < hip_angle < 180):\n",
    "                        self.speak_signal.emit(\"请抬腿\")\n",
    "                        self.leg_raised = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # if leg_raised:\n",
    "                    #     # 如果髋关节补角小于150度\n",
    "                    #     if hip_angle_complement < 150:\n",
    "                    #         if knee_angle_complement < 170:\n",
    "                    #             speak(\"膝关节未伸直\")\n",
    "                    #         elif hip_angle > 55:\n",
    "                    #             if hip_angle < 70:\n",
    "                    #                 speak(\"正常\")\n",
    "                    #             if hip_angle > 70:\n",
    "                    #                 speak(\"优秀\")\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"姿势检测错误: {str(e)}\")\n",
    "\n",
    "            self.current_frame = annotated_frame\n",
    "\n",
    "            # 转换视频帧格式\n",
    "            rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            h, w, ch = rgb_image.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)\n",
    "            self.change_pixmap.emit(qt_image)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_ui()\n",
    "        self.init_video_thread()\n",
    "\n",
    "    def init_ui(self):\n",
    "        self.setWindowTitle(\"智能姿势检测系统\")\n",
    "        self.setGeometry(100, 100, 1280, 720)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            background: #2C3E50; \n",
    "            color: #ECF0F1;\n",
    "            QLineEdit {\n",
    "                padding: 12px;\n",
    "                font-size: 16px;\n",
    "                border: 2px solid #3498DB;\n",
    "                border-radius: 5px;\n",
    "            }\n",
    "            QPushButton {\n",
    "                background: #3498DB;\n",
    "                padding: 12px;\n",
    "                border-radius: 5px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background: #2980B9;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "        # 创建UI组件\n",
    "        self.image_label = QLabel()\n",
    "        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.id_input = QLineEdit(placeholderText=\"输入受试者编号\")\n",
    "        self.confirm_btn = QPushButton(\"确认编号\", clicked=self.validate_id)\n",
    "        self.capture_btn = QPushButton(\"立即拍照\", clicked=self.manual_save)\n",
    "        self.capture_btn.setStyleSheet(\"\"\"\n",
    "            QPushButton {\n",
    "                background: #27AE60;\n",
    "                padding: 12px;\n",
    "                border-radius: 5px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background: #219A52;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "        # 布局设置\n",
    "        top_layout = QHBoxLayout()\n",
    "        top_layout.addWidget(self.id_input)\n",
    "        top_layout.addWidget(self.confirm_btn)\n",
    "        top_layout.addWidget(self.capture_btn)\n",
    "\n",
    "        main_layout = QVBoxLayout()\n",
    "        main_layout.addLayout(top_layout)\n",
    "        main_layout.addWidget(self.image_label, stretch=1)\n",
    "        \n",
    "        container = QWidget()\n",
    "        container.setLayout(main_layout)\n",
    "        self.setCentralWidget(container)\n",
    "\n",
    "    def manual_save(self):\n",
    "        \"\"\"手动保存按钮点击处理\"\"\"\n",
    "        if not self.id_input.text().strip():\n",
    "            QMessageBox.warning(self, \"警告\", \"请先输入并确认受试者编号\")\n",
    "            return\n",
    "        self.video_thread.capture_signal.emit()\n",
    "\n",
    "    def init_video_thread(self):\n",
    "        self.video_thread = VideoThread()\n",
    "        self.video_thread.change_pixmap.connect(self.update_frame)\n",
    "        self.video_thread.save_signal.connect(self.save_image)\n",
    "        self.video_thread.speak_signal.connect(self.speak)\n",
    "        self.video_thread.error_signal.connect(self.show_error)\n",
    "        self.video_thread.start()\n",
    "\n",
    "    def validate_id(self):\n",
    "        if not self.id_input.text().strip():\n",
    "            QMessageBox.warning(self, \"输入错误\", \"受试者编号不能为空\")\n",
    "            return\n",
    "        QMessageBox.information(self, \"验证成功\", \"编号已确认，可以开始检测\")\n",
    "\n",
    "    @pyqtSlot(QImage)\n",
    "    def update_frame(self, image):\n",
    "        self.image_label.setPixmap(\n",
    "            QPixmap.fromImage(image).scaled(\n",
    "                1280, 720, \n",
    "                Qt.AspectRatioMode.KeepAspectRatio,\n",
    "                Qt.TransformationMode.SmoothTransformation\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @pyqtSlot()\n",
    "    def save_image(self):\n",
    "        subject_id = self.id_input.text().strip()\n",
    "        if not subject_id:\n",
    "            self.speak(\"未识别到受试者编号\")\n",
    "            return\n",
    "\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_type = \"manual\" if self.sender() == self.capture_btn else \"auto\"\n",
    "        filename = f\"{subject_id}_{save_type}_{timestamp}.png\"\n",
    "        cv2.imwrite(filename, self.video_thread.current_frame)\n",
    "        self.speak(f\"已保存姿势数据: {filename}\")\n",
    "\n",
    "    @pyqtSlot(str)\n",
    "    def speak(self, message):\n",
    "        engine.say(message)\n",
    "        engine.runAndWait()\n",
    "\n",
    "    @pyqtSlot(str)\n",
    "    def show_error(self, message):\n",
    "        QMessageBox.critical(self, \"硬件错误\", message)\n",
    "        self.close()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.video_thread.stop()\n",
    "        self.video_thread.wait(3000)\n",
    "        event.accept()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    app.setFont(QFont(\"Arial\", 12))\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    sys.exit(app.exec())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rehab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
